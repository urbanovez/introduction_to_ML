{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('features/features.csv', index_col='match_id')\n",
    "features_test = pd.read_csv('features_test.csv', index_col='match_id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пропущенные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_blood_player2            0.452402\n",
       "radiant_flying_courier_time    0.282619\n",
       "dire_flying_courier_time       0.268415\n",
       "first_blood_time               0.201100\n",
       "first_blood_team               0.201100\n",
       "first_blood_player1            0.201100\n",
       "dire_bottle_time               0.166029\n",
       "radiant_bottle_time            0.161380\n",
       "radiant_first_ward_time        0.018883\n",
       "dire_first_ward_time           0.018780\n",
       "radiant_courier_time           0.007117\n",
       "dire_courier_time              0.006953\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T['count'][data.describe().T['count'] < len(data)].sort_values().apply(lambda x: (len(data) - x) / len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные за 5 минут игры\n",
    "#### справа вероятность того, что событие не произойдет за первые 5 минут игры\n",
    "\n",
    "* **first_blood_player2** - второй игрок, причастный к событию. Отсутвует, потому что за 5 минут никого не убили /убил только один игрок.\n",
    "* **radiant_flying_courier_time** - время приобретения предмета \"flying_courier\". Отсутствует, потому что за 5 минут не был куплен.\n",
    "* **dire_flying_courier_time** - аналогично со стороны другой команды\n",
    "* **first_blood_time** - игровое время первой крови. Отсутсвует, потому что за 5 минут никого не убили\n",
    "* **first_blood_team** - аналогичная причина\n",
    "* **first_blood_player1** - аналогичная причина\n",
    "* **dire_bottle_time** - время первого приобретения командой предмета \"bottle\". Отсутствует, потому что никто не купил за  5 минут.\n",
    "* **radiant_bottle_time** - аналогичная причина.\n",
    "* **radiant_first_ward_time** -  время установки командой первого \"наблюдателя\". Отсутствует, потому что никто не установил за  5 минут.\n",
    "* **dire_first_ward_time** - аналогичная причина для другой команды\n",
    "* **radiant_courier_time** - время приобретения предмета \"courier\".Отсутствует, потому что за 5 минут не был куплен.\n",
    "* **dire_courier_time** - аналогичная причина для другой команды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.fillna(0,inplace = True)\n",
    "data.drop(['duration', \n",
    "         'tower_status_radiant', \n",
    "         'tower_status_dire', \n",
    "         'barracks_status_radiant', \n",
    "         'barracks_status_dire'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data\n",
    "#y_train = data['radiant_win'].to_frame()\n",
    "#y_train = data['radiant_win'].to_numpy\n",
    "\n",
    "y_train = data['radiant_win'].values\n",
    "X_train.drop(['radiant_win'],axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**radiant_win** - целевая переменная\n",
    "\n",
    "## Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#10 Time:  0:00:41.126477\n",
      "SCORES:  [0.66250835 0.66515185 0.65618036 0.66989025 0.67549534]    mean:   0.6658452314180121\n",
      "\n",
      "#20 Time:  0:01:19.380765\n",
      "SCORES:  [0.67432171 0.68895313 0.68274943 0.6809305  0.68524744]    mean:   0.6824404426871318\n",
      "\n",
      "#30 Time:  0:01:59.220209\n",
      "SCORES:  [0.68703857 0.69300469 0.68887393 0.69159849 0.68852907]    mean:   0.6898089476941627\n",
      "\n",
      "#50 Time:  0:03:17.936684\n",
      "SCORES:  [0.69987485 0.69585647 0.68978932 0.70056541 0.69801329]    mean:   0.6968198689979208\n",
      "\n",
      "#100 Time:  0:06:34.240674\n",
      "SCORES:  [0.69684333 0.7061727  0.71073256 0.70831198 0.70992228]    mean:   0.7063965710100316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "cv = KFold(n_splits = 5, shuffle=True)\n",
    "scores = list()\n",
    "for k in (10,20,30,50,100):\n",
    "    start_time = datetime.now()\n",
    "    model = GradientBoostingClassifier(n_estimators=k)\n",
    "    scores.append(cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')) \n",
    "    print ('#' + str(k) + ' Time:  ' + str(datetime.now() - start_time))\n",
    "    print ('SCORES:  ' + str(scores[-1]) + '    mean:   ' + str(np.mean(scores[-1])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Время выполнения Кросс-валидации для разного количества деревьев с соответствующими значениями метрики AUC-ROC\n",
    "\n",
    "\n",
    "Имеет смысл использовать больше 30 деревьев, так как с увелечением количества деревьев увеличиваются значения метрики AUC-ROC\n",
    "Что делать, чтобы ускорить его обучение при увеличении количества деревьев:\n",
    "*Использовать для обучения и кросс-валидации не всю выборку, а некоторое ее подмножество — например, половину объектов. *Подмножество лучше всего брать случайным, а не формировать его из первых m объектов.\n",
    "*Попробовать упростить модель — например, уменьшить глубину деревьев в градиентом бустинге (max_depth).\n",
    "\n",
    "## Логистическая регрессия\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0.001 Time:  0:00:02.073783\n",
      "SCORES:  [0.71186626 0.71410819 0.71357438 0.72176492 0.72011222]    mean:   0.7162851929384727\n",
      "\n",
      "#0.01 Time:  0:00:02.713743\n",
      "SCORES:  [0.72328302 0.71348524 0.71574974 0.71529435 0.71366313]    mean:   0.7162950961683041\n",
      "\n",
      "#0.1 Time:  0:00:03.025908\n",
      "SCORES:  [0.71816765 0.7126706  0.71585986 0.71820783 0.71619713]    mean:   0.7162206159282769\n",
      "\n",
      "#1 Time:  0:00:02.900245\n",
      "SCORES:  [0.71675218 0.71390773 0.71505026 0.7217247  0.7152278 ]    mean:   0.7165325335142194\n",
      "\n",
      "#10 Time:  0:00:02.825443\n",
      "SCORES:  [0.71922478 0.7169698  0.71513777 0.71093017 0.7186686 ]    mean:   0.7161862231434173\n",
      "\n",
      "#100 Time:  0:00:02.909258\n",
      "SCORES:  [0.71929308 0.71275094 0.71608428 0.71538901 0.71924203]    mean:   0.7165518679271665\n",
      "\n",
      "#1000 Time:  0:00:02.863349\n",
      "SCORES:  [0.71444112 0.71937985 0.71797177 0.71685847 0.71429735]    mean:   0.7165897109520365\n",
      "\n",
      "#10000 Time:  0:00:02.960084\n",
      "SCORES:  [0.7122857  0.71767674 0.71424461 0.7193226  0.71799037]    mean:   0.7163040032090848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "scores = list()\n",
    "\n",
    "for c in [10 ** i for i in range(-3, 5)]:\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    model = LogisticRegression(C = c)\n",
    "    scores.append(cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc'))\n",
    "    \n",
    "    print ('#' + str(c) + ' Time:  ' + str(datetime.now() - start_time))\n",
    "    print ('SCORES:  ' + str(scores[-1]) + '    mean:   ' + str(np.mean(scores[-1])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Время выполнения Кросс-Валидации для разного параметра регуляризации С с соответствующими значениями метрики AUC-ROC\n",
    "\n",
    "\n",
    "Лучшее значение метрики AUC-ROC = 0.716 при C = 1. Это выше чем при бустинге со 100 деревьявми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\n",
    "    'lobby_type',\n",
    "    'r1_hero',\n",
    "    'r2_hero',\n",
    "    'r3_hero',\n",
    "    'r4_hero',\n",
    "    'r5_hero',\n",
    "    'd1_hero',\n",
    "    'd2_hero',\n",
    "    'd3_hero',\n",
    "    'd4_hero',\n",
    "    'd5_hero',\n",
    "],axis = 1, inplace = True)\n",
    "\n",
    "X_train = data\n",
    "X_train = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0.001 Time:  0:00:01.827617\n",
      "SCORES:  [0.71645095 0.71440459 0.71682396 0.71771616 0.71564768]    mean:   0.7162086657171703\n",
      "\n",
      "#0.01 Time:  0:00:02.661887\n",
      "SCORES:  [0.70912653 0.71675918 0.71731267 0.71714265 0.72154518]    mean:   0.7163772417330774\n",
      "\n",
      "#0.1 Time:  0:00:02.625977\n",
      "SCORES:  [0.71896721 0.71754684 0.7221589  0.71268791 0.71200606]    mean:   0.7166733832005938\n",
      "\n",
      "#1 Time:  0:00:02.617007\n",
      "SCORES:  [0.71650863 0.71565283 0.71390478 0.72040674 0.71553033]    mean:   0.7164006603859998\n",
      "\n",
      "#10 Time:  0:00:02.666868\n",
      "SCORES:  [0.7197465  0.71984904 0.71698703 0.71058957 0.71544023]    mean:   0.7165224736844957\n",
      "\n",
      "#100 Time:  0:00:02.669912\n",
      "SCORES:  [0.71637253 0.71694294 0.71493268 0.71664862 0.71685134]    mean:   0.716349623162843\n",
      "\n",
      "#1000 Time:  0:00:02.688810\n",
      "SCORES:  [0.71730523 0.71513047 0.71645226 0.71612433 0.71832224]    mean:   0.7166669039740172\n",
      "\n",
      "#10000 Time:  0:00:02.617597\n",
      "SCORES:  [0.71940238 0.71208107 0.71940506 0.7113497  0.7198608 ]    mean:   0.7164197991848217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = list()\n",
    "\n",
    "for c in [10 ** i for i in range(-3, 5)]:\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    model = LogisticRegression(C = c)\n",
    "    scores.append(cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc'))\n",
    "    \n",
    "    print ('#' + str(c) + ' Time:  ' + str(datetime.now() - start_time))\n",
    "    print ('SCORES:  ' + str(scores[-1]) + '    mean:   ' + str(np.mean(scores[-1])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее значение метрики AUC-ROC = 0.7164 при C = 1000 и это лучше, чем было без удаления категориальных признаков, однако значение регуляризации тоже несущественно поменялось, потому что мы не ставили random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 уникальных героя\n"
     ]
    }
   ],
   "source": [
    "print(str(len(np.unique(data[['r' + str(i) + '_hero' for i in range(1,6)]]))) + ' уникальных героя')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_pick = np.zeros((data.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "data.drop([\n",
    "    'lobby_type',\n",
    "    'r1_hero',\n",
    "    'r2_hero',\n",
    "    'r3_hero',\n",
    "    'r4_hero',\n",
    "    'r5_hero',\n",
    "    'd1_hero',\n",
    "    'd2_hero',\n",
    "    'd3_hero',\n",
    "    'd4_hero',\n",
    "    'd5_hero',\n",
    "],axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.54436416e+00,  1.40080818e+00,  1.52597175e+00, ...,\n",
       "        -4.83865990e-03,  0.00000000e+00,  8.46061344e-04],\n",
       "       [-2.54045236e+00,  5.01313538e-01, -8.01392943e-02, ...,\n",
       "        -4.83865990e-03,  0.00000000e+00,  8.46061344e-04],\n",
       "       [-2.53923104e+00,  5.01313538e-01,  1.51070097e-01, ...,\n",
       "        -4.83865990e-03,  0.00000000e+00,  8.46061344e-04],\n",
       "       ...,\n",
       "       [ 1.09874571e+00,  5.01313538e-01,  2.92266672e-01, ...,\n",
       "        -4.83865990e-03,  0.00000000e+00,  1.64609695e+00],\n",
       "       [ 1.09895204e+00, -3.98181106e-01, -1.73682025e-01, ...,\n",
       "        -4.83865990e-03,  0.00000000e+00,  8.46061344e-04],\n",
       "       [ 1.10264790e+00, -3.98181106e-01, -3.18408515e-01, ...,\n",
       "        -4.83865990e-03,  0.00000000e+00, -1.64440483e+00]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.hstack((data.values, X_pick))\n",
    "X_train = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0.001 Time:  0:00:03.790863\n",
      "SCORES:  [0.75190132 0.74459114 0.75545409 0.75135103 0.75501958]    mean:   0.75166343091473\n",
      "\n",
      "#0.01 Time:  0:00:05.659863\n",
      "SCORES:  [0.75292304 0.75308733 0.75533016 0.74740161 0.75118894]    mean:   0.7519862156189381\n",
      "\n",
      "#0.1 Time:  0:00:06.148560\n",
      "SCORES:  [0.75226126 0.75052564 0.74944457 0.75584924 0.75070509]    mean:   0.7517571593135237\n",
      "\n",
      "#1 Time:  0:00:06.308131\n",
      "SCORES:  [0.74612417 0.74919029 0.75585474 0.75025009 0.75738259]    mean:   0.7517603763946967\n",
      "\n",
      "#10 Time:  0:00:06.271230\n",
      "SCORES:  [0.75595914 0.74969909 0.75079595 0.75660447 0.74663206]    mean:   0.7519381438621213\n",
      "\n",
      "#100 Time:  0:00:06.129607\n",
      "SCORES:  [0.75326134 0.75294715 0.75518061 0.74912212 0.74911968]    mean:   0.7519261815511508\n",
      "\n",
      "#1000 Time:  0:00:06.096697\n",
      "SCORES:  [0.75278246 0.75160928 0.75283569 0.74964835 0.75141057]    mean:   0.7516572711560551\n",
      "\n",
      "#10000 Time:  0:00:06.133596\n",
      "SCORES:  [0.75687945 0.75049437 0.74888335 0.74886769 0.75387528]    mean:   0.7518000291659876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = list()\n",
    "\n",
    "for c in [10 ** i for i in range(-3, 5)]:\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    model = LogisticRegression(C = c)\n",
    "    scores.append(cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc'))\n",
    "    \n",
    "    print ('#' + str(c) + ' Time:  ' + str(datetime.now() - start_time))\n",
    "    print ('SCORES:  ' + str(scores[-1]) + '    mean:   ' + str(np.mean(scores[-1])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "При добавления \"мешка слов\" по героям качество заметно улучшается. Лучшее значение метрики AUC-ROC = 0.75198, при C = 0.01. Объясняется тем, что информация какой герой использовался в матче дает полезную информацию. \n",
    "\n",
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/features.csv',index_col='match_id')\n",
    "data.drop(['duration', \n",
    "         'tower_status_radiant', \n",
    "         'tower_status_dire', \n",
    "         'barracks_status_radiant', \n",
    "         'barracks_status_dire',\n",
    "         'radiant_win'\n",
    "        ], axis=1, inplace=True)\n",
    "\n",
    "data.fillna(0,inplace = True)\n",
    "\n",
    "X_pick = np.zeros((data.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "data.drop([\n",
    "    'lobby_type',\n",
    "    'r1_hero',\n",
    "    'r2_hero',\n",
    "    'r3_hero',\n",
    "    'r4_hero',\n",
    "    'r5_hero',\n",
    "    'd1_hero',\n",
    "    'd2_hero',\n",
    "    'd3_hero',\n",
    "    'd4_hero',\n",
    "    'd5_hero',\n",
    "],axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "X_train = np.hstack((data.values, X_pick))\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "###\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/features_test.csv',index_col='match_id')\n",
    "data.fillna(0,inplace = True)\n",
    "\n",
    "\n",
    "X_pick = np.zeros((data.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "data.drop([\n",
    "    'lobby_type',\n",
    "    'r1_hero',\n",
    "    'r2_hero',\n",
    "    'r3_hero',\n",
    "    'r4_hero',\n",
    "    'r5_hero',\n",
    "    'd1_hero',\n",
    "    'd2_hero',\n",
    "    'd3_hero',\n",
    "    'd4_hero',\n",
    "    'd5_hero',\n",
    "],axis = 1, inplace = True)\n",
    "\n",
    "X_test = np.hstack((data.values, X_pick))\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.01)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = model.predict_proba(X_test)\n",
    "submit = [submit[i][1] for i in range(0,len(submit))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max proba: 0.9963305890721924\n",
      "Min proba: 0.008721474723112774\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Max proba: ' + str(max(submit)))\n",
    "print('Min proba: ' + str(min(submit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data = submit, index = data.index, columns=['radiant_win']).to_csv('kaggle_submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат с kaggle - 0.75532"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
